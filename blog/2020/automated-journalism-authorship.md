# Who is the author of an AI-generated news article?

If you read major American newspapers such as Forbes or the Los Angeles Times, chances are you've already read a story entirely written by an AI-powered software system. This process is known as automated journalism, and highlights an important question about authorship: _Who is the author of an article written by a virtual agent?_. A 2005 study found that research participants attribute story credit to the programmers who developed the AI or the news organization publishing the story.

However, this is not the full picture. Since machine learning models require large amounts of training data that the agent "learns" from (and, in some cases depending on the implementation, the output is largely inspired by the training data), the human authors of said data are also worthy contenders for the credit.

As another example, Summly, a London-based startup founded in 2011 was acquired by Yahoo! for $30MM in 2013. At the name suggests, Summly specialized in summarizing news sources using AI-powered software. Using "thousands of sources", users could read algorithmically-generated summaries of news stories using their app. If a human was summarizing a news story, say from 20 paragraphs to 2 paragraphs, we wouldn't give them credit over the new story. In this case, the AI is essentially just a summarizing tool, except that it uses multiple, sometimes hundreds, of difference sources for each story. I would argue that the published summary should still be credited to the hundreds of authors of the data the AI used to generated summaries.

The most important reason why authorship is important is credibility. If you know the name of the author of an article in a major newspaper or magazine, you can find out more information about them, perhaps by visiting their social media handles. If you have any questions about their work, or found a mistake in their article, you can contact them directly. In the case of an article written by an unnamed virtual agent, the only option is to find the contact information of the publication.

In news articles written by virtual agents, there is "no visible indicator for readers to verify whether an article was written by a robot or human", which raises issues of transparency. Both Summly and related software claim the created work as their own, or strongly imply it by not citing individual source authors.
